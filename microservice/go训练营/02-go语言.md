- https://github.com/da440dil
- https://brunocalza.me/how-buffer-pool-works-an-implementation-in-go/
- Go语言第一深坑 - interface 与 nil 的比较: https://studygolang.com/articles/10635
- https://github.com/ardanlabs/gotraining/tree/master/topics/go
- https://www.ardanlabs.com/blog/2017/02/package-oriented-design.html
- 充血模型，贫血模型
- https://github.com/facebook/ent   --- ORM 框架
- https://github.com/google/wire
- 依赖管理： https://blog.golang.org/wire

### panic

- 业务代码几乎不会直接抛出panic

### 匿名方法，接口

### Goroutine

- 生命周期掌握
- mesi协议
- 内存屏障

> log.Fatal 调用了 os.Exit，会无条件终止程序；defers 不会被调用到

- 调用者确定是否使用goroutine，函数提供者不要使用goroutine
- 

### Memory Model

- 原子性和可见性
- https://golang.org/ref/mem
- cache line
- memory barrier
- [Go的内存模型 - 简书 (jianshu.com)](https://www.jianshu.com/p/5e44168f47a3)
- single machine word
- double write buffer
- vdso, mesi,nginx memory barrier
- intel pause 优化

### Detecting Race Conditions With Go

data race 是两个或多个 goroutine 访问同一个资源(如变量或数据结构)，并尝试对该资源进行读写而不考虑其他 goroutine。这种类型的代码可以创建您见过的最疯狂和最随机的 bug。通常需要大量的日志记录和运气才能找到这些类型的bug。

- go build -race
- go test -race
- go test -bench=. 

sync.waitGroup

- Mutex 源码使用

---

### sync.atomic

- Copy-On-Write 思路在微服务降级或者 local cache 场景中经常使用。写时复制指的是，写操作时候复制全量老数据到一个新的对象中，携带上本次新写的数据，之后利用原子替换(atomic.Value)，更新调用者的变量。来完成无锁访问共享数据。

---

### sync.Once

### sync.Pool

- ring buffer（定长FIFO）+双链表，头部只能写入，尾部可以并发读取

---

### errorgroup

- 我们把一个复杂的任务，尤其是依赖多个微服务 rpc 需要聚合数据的任务，分解为依赖和并行，依赖的意思为: 需要上游 a 的数据才能访问下游 b 的数据进行组合。但是并行的意思为: 分解为多个小任务并行执行，最终等全部执行完毕。
  https://pkg.go.dev/golang.org/x/sync/errgroup
- 核心原理: **利用 sync.Waitgroup 管理并行执行的 goroutine**
- 阅读源码

### Package Context

- context.WithValue

### channels

- channels 是一种类型安全的消息队列，充当两个 goroutine 之间的管道，将通过它同步的进行任意资源的交换。chan 控制 goroutines 交互的能力从而创建了 Go 同步机制。当**创建的 chan 没有容量时，称为无缓冲通道**。反过来，**使用容量创建的 chan 称为缓冲通道**。
  要了解通过 chan 交互的 goroutine 的同步行为是什么，我们需要知道通道的类型和状态。根据我们使用的是无缓冲通道还是缓冲通道，场景会有所不同，所以让我们单独讨论每个场景。
- 发送至close channel
- https://blog.golang.org/concurrency-timeouts

**If any given Send on a channel CAN cause the sending goroutine to block:**

- Not allowed to use a Buffered channel larger than 1.
  Buffers larger than 1 must have reason/measurements.
  Must know what happens when the sending goroutine blocks.
  
  If any given Send on a channel WON’T cause the sending goroutine to block:
  You have the exact number of buffers for each send.
  Fan Out pattern
  You have the buffer measured for max capacity.
  Drop pattern

- Less is more with buffers.
  Don’t think about performance when thinking about buffers.
  Buffers can help to reduce blocking latency between signaling.
  Reducing blocking latency towards zero does not necessarily mean better throughput.
  If a buffer of one is giving you good enough throughput then keep it.
  Question buffers that are larger than one and measure for size.
  Find the smallest buffer possible that provides good enough throughput.
