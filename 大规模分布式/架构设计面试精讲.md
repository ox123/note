> 课程：https://kaiwu.lagou.com/course/courseInfo.htm?courseId=592#/detail/pc?id=6051

### 对系统架构设计的认知

- 落地没有实际经验，拔高没有理论支撑。
- 为什么做架构拆分 
  - 为什么做架构拆分？通常最直接目的就是做系统之间解耦、子系统之间解耦，或模块之间的解耦。
  - 为什么要做系统解耦？系统解耦后，使得原本错综复杂的调用逻辑能有序地分布到各个独立的系统中，从而使得拆封后的各个系统职责更单一，功能更为内聚。
  - 为什么要做职责单一？因为职责单一的系统功能逻辑的迭代速度会更快，会提高研发团队响应业务需求的速度，也就是提高了团队的开发效率。
  - 为什么要关注开发效率？研发迭代效率的提升是任何一家公司在业务发展期间都最为关注的问题，所以从某种程度上看，架构拆分是系统提效最直接的手段。

### 提高分析系统问题的认知

##### 因为对于系统技术架构升级的问题，业务方、管理者和技术人员的关注点是不同的。

- 业务方的诉求是在技术升级后，系统有能力迭代功能来满足市场的要求，所以关注点在系统能力。

- 管理者的诉求是在技术升级后，系统研发团队的开发效能得到提升，所以关注点在人效管理。

- 作为技术人员的你，需要找到自己做系统设计的立足点，来满足不同人对技术的诉求，而这个立足点通常就是系统设计原则。

  

**系统的设计原则不是乱提出来的，而是针对系统现阶段业务发展带来的主要矛盾提出，才会更有价值且被认可。** 



架构最重要的是要解决本质复杂性，这包括人的**复杂性和业务的复杂性**。

**中高级研发工程师与架构师标准**

![image-20210102230538835](assets/image-20210102230538835.png)

### 能力边界认知

##### 研发工程师和架构师能驾驭的边界可以如下概括：

一个中高级研发工程师对系统的驾驭边界至少是模块或者子系统层面；

一个架构师对系统的驾驭边界至少是全系统层面；

一个高级架构师对系统的驾驭边界至少是某一领域层面。

---

产品业务发展快速、系统越来越多、协作效率越来越低。

![image-20210102233352526](assets/image-20210102233352526.png)

----> 分析问题-》提出对应的解决方案-》针对不同的解决方案的优缺点汇总-》

### 分析系统架构的角度

- 在回答系统复杂度来源的时候，要注意结合具体的业务场景和业务发展阶段来阐述。业务场景表明了业务的独特性，发展阶段表明了业务的成熟度，因为同一业务场景在不同阶段产生的矛盾也是不同的。

- 在回答解决方案的时候，有价值的解决方案一定是建立在明确复杂度来源基础之上的。所以在设计架构的时候才分主要问题和次要问题，主要问题是必须要解决的点，次要问题可以根据实际情况进行取舍。

- 在回答如何评估架构方案时，至少要从功能性和非功能性两个角度出发判断方案的合理性。对于很难决策的方案，要从更高的视角（比如技术负责人、业务负责人的角度）进行考量。

- 在技术实现的细节上，要尽量讲出技术的实现原理，不要浮于表面的框架组合。



### 分布式数据存储问题

1. 数据分片
   - Hash，直接hash方法缺点是由于节点再变换导致如果节点有变动那么久要重新hash问题。 解决方案是使用**一致性hash**
     - **一致性hash**，它是指将存储节点和数据都映射到一个首尾相连的哈希环上。存储节点一般可以根据 IP 地址进行 Hash 计算，数据的存储位置是从数据映射在环上的位置开始，依照顺时针方向所找到的第一个存储节点。
   - Range
   - hash很均匀，range利于热点，所以也可以两者做结合。
2. 数据复制
3. 数据一致性

![image-20210120215719904](assets/image-20210120215719904.png)



### 分布式事务

1. 2PC提交
2. 3PC提交
3. 基于消息队列实现
   - 消息ack导致丢失
   - 双向确认确保消息不丢失



### 分布式锁

<img src="assets/image-20210125232715842.png" alt="image-20210125232715842" style="zoom: 50%;" />

分布式锁可能出现的问题

- **可用问题**：无论何时都要保证锁服务的可用性（这是系统正常执行锁操作的基础）。
- **死锁问题**：客户端一定可以获得锁，即使锁住某个资源的客户端在释放锁之前崩溃或者网络不可达（这是避免死锁的设计原则）。
- **脑裂问题**：集群同步时产生的数据不一致，导致新的进程有可能拿到锁，但之前的进程以为自己还有锁，那么就出现两个进程拿到了同一个锁的问题。

分布式锁设计原则

- **互斥性**：即在分布式系统环境下，对于某一共享资源，需要保证在同一时间只能一个线程或进程对该资源进行操作。
- **高可用**：也就是可靠性，锁服务不能有单点风险，要保证分布式锁系统是集群的，并且某一台机器锁不能提供服务了，其他机器仍然可以提供锁服务。
- **锁释放**：具备锁失效机制，防止死锁。即使出现进程在持有锁的期间崩溃或者解锁失败的情况，也能被动解锁，保证后续其他进程可以获得锁。
- **可重入**：一个节点获取了锁之后，还可以再次获取整个锁资源。

##### 基于MySQL分布式锁

- select id from order where order_id = xxx for update

  基于关系型数据库实现分布式锁比较简单，不过你要注意，基于 MySQL 行锁的方式会出现交叉死锁，比如事务 1 和事务 2 分别取得了记录 1 和记录 2 的排它锁，然后事务 1 又要取得记录 2 的排它锁，事务 2 也要获取记录 1 的排它锁，那这两个事务就会因为相互锁等待，产生死锁。

  ![image-20210125233120928](assets/image-20210125233120928.png)

- **数据库的事务隔离级别**

如果你想让系统支持海量并发，那数据库的并发处理能力就尤为重要，而影响数据库并发能力最重要的因素是**数据库的事务隔离机制**。

数据库的四种隔离级别从低到高分别是：

- 读未提交（READ UNCOMMITTED）；
- 读已提交（READ COMMITTED）；
- 可重复读（REPEATABLE READ）；
- 可串行化（SERIALIZABLE）。

其中，可串行化操作就是按照事务的先后顺序，排队执行，然而一个事务操作可能要执行很久才能完成，这就没有并发效率可言了，**所以数据库隔离级别越高，系统的并发性能就越差。**



##### 基于分布式缓存实现分布式锁

在加锁的过程中，实际上就是在给 Key 键设置一个值，为避免死锁，还要给 Key 键设置一个过期时间。

```
SET lock_key unique_value NX PX 10000
```

- lock_key 就是 key 键；
- unique_value 是客户端生成的唯一的标识；
- NX 代表只在 lock_key 不存在时，才对 lock_key 进行设置操作；
- PX 10000 表示设置 lock_key 的过期时间为 10s，这是为了避免客户端发生异常而无法释放锁。

而解锁的过程就是将 lock_key 键删除，但不能乱删，要保证执行操作的客户端就是加锁的客户端。而这个时候， unique_value 的作用就体现出来，实现方式可以通过 lua 脚本判断 unique_value 是否为加锁客户端。

选用 Lua 脚本是为了保证解锁操作的原子性。因为 Redis 在执行 Lua 脚本时，可以以原子性的方式执行，从而保证了锁释放操作的原子性。

复制代码

```
// 释放锁时，先比较 unique_value 是否相等，避免锁的误释放
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
```

以上，就是基于 Redis 的 SET 命令和 Lua 脚本在 Redis 单节点上完成了分布式锁的加锁、解锁

- **如何合理设置超时时间**

通过超时时间来控制锁的失效时间，不太靠谱，比如在有些场景中，一个线程 A 获取到了锁之后，由于业务代码执行时间可能比较长，导致超过了锁的超时时间，自动失效，后续线程 B 又意外的持有了锁，当线程 A 再次恢复后，通过 del 命令释放锁，就错误的将线程 B 中同样 key 的锁误删除了。

![image-20210126235347063](assets/image-20210126235347063.png)

**那么如何合理设置超时时间呢？** 你可以基于续约的方式设置超时时间：先给锁设置一个超时时间，然后启动一个守护线程，让守护线程在一段时间后，重新设置这个锁的超时时间。实现方式就是：写一个守护线程，然后去判断锁的情况，当锁快失效的时候，再次进行续约加锁，当主线程执行完成后，销毁续约锁即可。

**解答“实践操作类面试题”，一定要结合理论和落地实践，要做到即有理也有据，有理表示要有分析问题的能力，有据表示具备落地实战的经验。**



### RPC 接口的超时问题

- **结合 TP99 请求耗时**：首先如果你要回答“超时时间设置和重传次数问题”，需要根据每一个微服务 TP99 的请求耗时，以及业务场景进行综合衡量。

- **RPC 调用方式**：你要站在业务场景下，讲清楚网关调用各下游服务的串并行方式，服务之间是否存在上下服务依赖。

- **分析核心服务**：分析出哪些是核心服务，哪些是非核心服务，核心服务是否有备用方案，非核心服务是否有降级策略。

**一定要结合理论和落地实践，要做到即有理也有据，有理表示要有分析问题的能力，有据表示具备落地实战的经验**

### 分析RPC性能问题

- **优化 RPC 的网络通信性能**： 高并发下选择高性能的网络编程 I/O 模型。
- **选型合适的 RPC 序列化方式**： 选择合适的序列化方式，进而提升封包和解包的性能。

### 一次完整RPB调用流程

- 调用方持续把请求参数对象序列化成二进制数据，经过 TCP 传输到服务提供方；

- 服务提供方从 TCP 通道里面接收到二进制数据；

- 根据 RPC 协议，服务提供方将二进制数据分割出不同的请求数据，经过反序列化将二进制数据逆向还原出请求对象，找到对应的实现类，完成真正的方法调用；

- 然后服务提供方再把执行结果序列化后，回写到对应的 TCP 通道里面；

- 调用方获取到应答的数据包后，再反序列化成应答对象。

![image-20210210235343323](assets/image-20210210235343323.png)

### BIO网络模型

- Socket 连接数量受限，不适用于高并发场景；

- 有两处阻塞，分别是等待用户发起连接，和等待用户发送数据。



### 消息丢失问题

- **消息生产阶段**： 从消息被生产出来，然后提交给 MQ 的过程中，只要能正常收到 MQ Broker 的 ack 确认响应，就表示发送成功，所以只要处理好返回值和异常，这个阶段是不会出现消息丢失的。

- **消息存储阶段**： 这个阶段一般会直接交给 MQ 消息中间件来保证，但是你要了解它的原理，比如 Broker 会做副本，保证一条消息至少同步两个节点再返回 ack（这里涉及数据一致性原理，我在 04 讲中已经讲过，在面试中，你可以灵活延伸）。

- **消息消费阶段**： 消费端从 Broker 上拉取消息，只要消费端在收到消息后，不立即发送消费确认给 Broker，而是等到执行完业务逻辑后，再发送消费确认，也能保证消息的不丢失。

![image-20210211001641363](assets/image-20210211001641363.png)

### 消息积压处理

- 如果是线上突发问题，要临时扩容，增加消费端的数量，与此同时，降级一些非核心的业务。通过扩容和降级承担流量
- 在扩容消费者的实例数的同时，必须同步扩容主题 Topic 的分区数量，确保消费者的实例数和分区数相等。如果消费者的实例数超过了分区数，由于分区是单线程消费，所以这样的扩容就没有效果。

### 抢购系统

![image-20210211004648177](assets/image-20210211004648177.png)