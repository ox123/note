- [kafka读写速度快](https://mp.weixin.qq.com/s/B0RjuajTKe94iz6FCRn1Fw)
- [Why Kafka Is so Fast](https://medium.com/swlh/why-kafka-is-so-fast-bde0d987cd03)

- [Kafka Consumer 的实现]([http://luojinping.com/2017/11/12/Kafka-Consumer-%E7%9A%84%E5%AE%9E%E7%8E%B0/](http://luojinping.com/2017/11/12/Kafka-Consumer-的实现/))

  ---

  ### 问题定位

  - [kafka consumer消费卡顿](http://luojinping.com/2017/11/12/解决-Kafka-Consumer-卡顿的问题/)

- 之前碰到过一个问题，当时，大面积日志段同时间切分，导致瞬时打满磁盘 I/O 带宽。对此，所有人都束手无策，最终只能求助于日志段源码。
  - 最后，在 LogSegment 的 shouldRoll 方法中找到了解决方案：设置 Broker 端参数 **log.roll.jitter.ms** 值大于 0，即通过给日志段切分执行时间加一个扰动值的方式，来避免大量日志段在同一时刻执行切分动作，从而显著降低磁盘 I/O。
- 