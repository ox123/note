### 消息队列涉及知识

- 必读文章：https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying

![image-20200821192824091](assets/image-20200821192824091.png)

### 消息队列问题

- 引入消息队列带来的延迟问题；
- 增加了系统的复杂度；
- 可能产生数据不一致的问题。

### 秒杀系统

**使用消息队列隔离网关和后端服务，以达到流量控制和保护后端服务的目的**

<img src="assets/image-20200821195244942.png" alt="image-20200821195244942" style="zoom: 50%;" />

- 异步处理
- 流量限制
- 服务解耦
- 

**令牌桶控制流量的原理是： 单位时间内只发放固定数量的令牌到令牌桶中，规定服务在处理请求之前必须先从令牌桶中拿出一个令牌，如果令牌桶中没有令牌，则拒绝请求。这样就保证单位时间内，能处理的请求不超过发放令牌的数量，起到了流量控制的作用。**（参考实现：https://blog.csdn.net/king0406/article/details/103129063）

<img src="assets/image-20200821195911097.png" alt="image-20200821195911097" style="zoom: 50%;" />

### 延迟任务

Note: silvan bullet, 万金油

### 消息队列选型

- 消息的可靠传递：确保不丢消息；
- Cluster：支持集群，确保不会因为某个节点宕机导致服务不可用，当然也不能丢消息；
- 性能：具备足够好的性能，能满足绝大多数场景的性能要求。
- **选择中间件的考量维度：可靠性，性能，功能，可运维行，可拓展性，是否开源及社区活跃度***

#### rabbitmq

- 对消息堆积支持不友好
- 性能相对来说不是最好
- 内核的语言相对小众erlang

#### rocketmq

- 不错的性能，稳定性和可靠性
- RocketMQ 对在线业务的响应时延做了很多的优化，大多数情况下可以做到毫秒级的响应，如果你的应用场景很在意响应时延，那应该选择使用 RocketMQ
- 每个主题在任意时刻，至多只能有一个消费者实例在进行消费，那就没法通过水平扩展消费者的数量来提升消费端总体的消费性能。为了解决这个问题，RocketMQ 在主题下面增加了队列的概念。
- **每个主题包含多个队列，通过多个队列来实现多实例并行生产和消费。**需要注意的是，RocketMQ 只在队列上保证消息的有序性，主题层面是无法保证消息的严格顺序的。
- 

#### kafka

- 可靠性、稳定性和功能特性等方面都可以满足绝大多数场景的需求
- Kafka 与周边生态系统的兼容性是最好的没有之一，尤其在大数据和流计算领域，几乎所有的相关开源软件系统都会优先支持 Kafka
- Kafka 不太适合在线业务场景

### topic与queue区别

- publish-subscribe pattern

<img src="assets/image-20200821205120844.png" alt="image-20200821205120844" style="zoom: 50%;" />

- 它们最大的区别其实就是，一份消息数据能不能被消费多次的问题。

- rabbitmq没有topic模型，而是使用队列模型，至于多个消费者需要消费消息，通过exchange配置路由目的队列实现。同一份消息如果需要被多个消费者来消费，需要配置 Exchange 将消息发送到多个队列，每个队列中都存放一份完整的消息数据，可以为一个消费者提供消费服务。这也可以变相地实现新发布 - 订阅模型中，“一份消息数据可以被多个订阅者来多次消费”这样的功能。

  <img src="assets/image-20200821205626893.png" alt="image-20200821205626893" style="zoom:50%;" />

- rocketmq 消息模型

  <img src="assets/image-20200821210426426.png" alt="image-20200821210426426" style="zoom:67%;" />

### 消息队列中的事务（分布式事务）

- **消息队列中的“事务”，主要解决的是消息生产者和消息消费者的数据一致性问题。**

  ### 分布式事务基本特征

  一个严格意义的事务实现，应该具有 4 个属性：原子性、一致性、隔离性、持久性。这四个属性通常称为 ACID 特性。

  - **原子性**，是指一个事务操作不可分割，要么成功，要么失败，不能有一半成功一半失败的情况。

  - **一致性**，是指这些数据在事务执行完成这个时间点之前，读到的一定是更新前的数据，之后读到的一定是更新后的数据，不应该存在一个时刻，让用户读到更新过程中的数据。

  - **隔离性**，是指一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对正在进行的其他事务是隔离的，并发执行的各个事务之间不能互相干扰，这个有点儿像我们打网游中的副本，我们在副本中打的怪和掉的装备，与其他副本没有任何关联也不会互相影响。

  - **持久性**，是指一个事务一旦完成提交，后续的其他操作和故障都不会对事务的结果产生任何影响。

####  kafka事务执行流程图

<img src="assets/image-20200821213708653.png" alt="image-20200821213708653" style="zoom:50%;" />

- **半消息***：消息发送之后消费者看不到，订单系统处理之后执行commit之后，购物车系统才可以看到对应的消息
- 如果第4步执行提交失败之后，kafka直接抛出异常，客户端需要处理

##### rocketmq执行事务流程

![image-20200821214122302](assets/image-20200821214122302.png)

### rabbitmq实现事务

- https://www.rabbitmq.com/semantics.html



### 消息丢失

- 识别消息丢失

  - 使用拦截器在每个消息加上编号，在消费者端通过检测编号连续来检查是否丢失数据

- 生产到消费阶段

  <img src="assets/image-20200821220155791.png" alt="image-20200821220155791" style="zoom:50%;" />

- 发送阶段

  - 发送消息代码时，需要注意，正确处理返回值或者捕获异常，就可以保证这个阶段的消息不会丢失
  - 同步发送时，只要注意捕获异常即可
  - 异步发送时，则需要在回调方法里进行检查。这个地方是需要特别注意的，很多丢消息的原因就是，我们使用了异步发送，却没有在回调中检查发送结果。

- 存储阶段

  - 消息落盘，保证broker 宕机消息也不丢失。




### 重复消费

- **At most once**: 至多一次。消息在传递时，最多会被送达一次。换一个说法就是，没什么消息可靠性保证，允许丢消息。一般都是一些对消息可靠性要求不太高的监控场景使用，比如每分钟上报一次机房温度数据，可以接受数据少量丢失。
- **At least once**: 至少一次。消息在传递时，至少会被送达一次。也就是说，不允许丢消息，但是允许有少量重复消息出现。
- **Exactly once**：恰好一次。消息在传递时，只会被送达一次，不允许丢失也不允许重复，这个是最高的等级。

**设计幂等操作**

- 利用数据库的唯一约束实现幂等

- 为更新的数据设置前置条件

- 记录并检查操作

  记录并检查操作，也称为“Token 机制或者 GUID（全局唯一 ID）机制”，实现的思路特别简单：在执行数据更新操作之前，先检查一下是否执行过这个更新操作。在发送消息时，给每条消息指定一个全局唯一的 ID，消费时，先根据这个 ID 检查这条消息是否有被消费过，如果没有消费过，才更新数据，然后将消费状态置为已消费。



### 消息堆积额

- 发送端
  - 对于发送消息的业务逻辑，只需要注意设置合适的并发和批量大小，就可以达到很好的发送性能
  - 消息发送流程
    - 发送端准备数据、序列化消息、构造请求等逻辑的时间，也就是发送端在发送网络请求之前的耗时；
    - 发送消息和返回响应在网络传输中的耗时；
    - Broker 处理消息的时延。
  - 
- 消费端
  - 我们在设计系统的时候，一定要保证消费端的消费性能要高于生产端的发送性能，这样的系统才能健康的持续运行。
  - **在扩容 Consumer 的实例数量的同时，必须同步扩容主题中的分区（也叫队列）数量，确保 Consumer 的实例数和分区数量是相等的。**如果 Consumer 的实例数量超过分区数量，这样的扩容实际上是没有效果的。
- 能导致积压突然增加，最粗粒度的原因，只有两种：要么是发送变快了，要么是消费变慢了



### 异步提高吞吐率

- java： CompletableFuture 
- 

###  异步编程

- IO密集型： 磁盘操作

  - 磁盘IO

  - 网络IO

    - 同步网络IO模型

    ![image-20200906224756371](assets/image-20200906224756371.png)

    - 异步网络IO模型

      ![image-20200906225459409](assets/image-20200906225459409.png)

  - 需要更加关注高性能的异步网络传输。

- 计算密集型：使用CPU



### kafka可靠性--不丢失消息

- kafka只对“已提交”的消息(committed message)做有限度的持久化保证
  - 已提交消息
  - 有限度的持久化保证

##### 消费者端可靠性



##### 生产者端可靠性

- **如果是多线程异步处理消费消息，Consumer 程序不要开启自动提交位移，而是要应用程序手动提交位移**



### kafka拦截器

- 生产者实现类继承**org.apache.kafka.clients.producer.ProducerInterceptor**
  1. onSend：该方法会在消息发送之前被调用。如果你想在发送之前对消息“美美容”，这个方法是你唯一的机会。
  2. onAcknowledgement：该方法会在消息成功提交或发送失败之后被调用。还记得我在上一期中提到的发送回调通知 callback  吗？onAcknowledgement 的调用要早于 callback 的调用。值得注意的是，这个方法和 onSend  不是在同一个线程中被调用的，因此如果你在这两个方法中调用了某个共享可变对象，一定要保证线程安全哦。还有一点很重要，这个方法处在 Producer 发送的主路径中，所以最好别放一些太重的逻辑进去，否则你会发现你的 Producer TPS 直线下降。
- 消费者实现类继承**org.apache.kafka.clients.consumer.ConsumerInterceptor**
  1. onConsume：该方法在消息返回给 Consumer 程序之前调用。也就是说在开始正式处理消息之前，拦截器会先拦一道，搞一些事情，之后再返回给你。
  2. onCommit：Consumer 在提交位移之后调用该方法。通常你可以在该方法中做一些记账类的动作，比如打日志等。

##### 使用场景

- 客户端监控，监控一条消息从产生到消费的时延。
- 消息审计



- 统计消息时延拦截器

  生产者端

  ```java
  public class AvgLatencyProducerInterceptor implements ProducerInterceptor<String, String> {
      private Jedis jedis; // 省略 Jedis 初始化
      @Override
      public ProducerRecord<String, String> onSend(ProducerRecord<String, String> record) {
          jedis.incr("totalSentMessage");
          return record;
      }
      @Override
      public void onAcknowledgement(RecordMetadata metadata, Exception exception) {
      }
      @Override
      public void close() {
      }
      @Override
      public void configure(Map<java.lang.String, ?> configs) {
      }
  ```

  消费者端

  ```java
  public class AvgLatencyConsumerInterceptor implements ConsumerInterceptor<String, String> {
      private Jedis jedis; // 省略 Jedis 初始化
      @Override
      public ConsumerRecords<String, String> onConsume(ConsumerRecords<String, String> records) {
          long lantency = 0L;
          for (ConsumerRecord<String, String> record : records) {
              lantency += (System.currentTimeMillis() - record.timestamp());
          }
          jedis.incrBy("totalLatency", lantency);
          long totalLatency = Long.parseLong(jedis.get("totalLatency"));
          long totalSentMsgs = Long.parseLong(jedis.get("totalSentMessage"));
          jedis.set("avgLatency", String.valueOf(totalLatency / totalSentMsgs));
          return records;
      }
      @Override
      public void onCommit(Map<TopicPartition, OffsetAndMetadata> offsets) {
  
      }
      @Override
      public void close() {
  
      }
      @Override
  
      public void configure(Map<String, ?> configs) {
  ```

  #### 实验

  Producer 拦截器 onSend 方法的签名如下

  ```java
  public ProducerRecord<K, V> onSend(ProducerRecord<K, V> record)
  ```

  如果我实现的逻辑仅仅是 return null，你觉得 Kafka 会丢弃该消息，还是原封不动地发送消息？请动手试验一下，看看结果是否符合你的预期。

### 网络

##### TCP连接

- 在创建KafkaProducer实例时创建
- 1. 更新元数据
  2. 在消息发送时

##### 关闭TCP连接

1. 用户主动关闭
   - 主动关闭实际上是广义的主动关闭，甚至包括用户调用 kill -9 主动“杀掉”Producer 应用。当然最推荐的方式还是调用 producer.close() 方法来关闭。
2. kafka自动关闭
   - Producer 端参数 connections.max.idle.ms 的值有关。默认情况下该参数值是 9 分钟，即如果在 9 分钟内没有任何请求“流过”某个 TCP 连接，那么 Kafka 会主动帮你把该 TCP 连接关闭



### 可靠性

- 最多一次（at most once）：消息可能会丢失，但绝不会被重复发送。

- 至少一次（at least once）：消息不会丢失，但有可能被重复发送。

- 精确一次（exactly once）：消息不会丢失，也不会被重复发送。

- Kafka 是怎么做到精确一次的呢？简单来说，这是通过两种机制：

  - 幂等性（Idempotence）

    - 其最大的优势在于我们可以安全地重试任何幂等性操作，反正它们也不会破坏我们的系统状态

    - 配置

      ```java
      props.put(“enable.idempotence”, ture) 或者
      props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG， true)。
      ```

      它只能保证**单分区上的幂等性**，即一个幂等性 Producer  能够保证某个主题的一个分区上不出现重复消息，它无法实现多个分区的幂等性。其次，**它只能实现单会话上的幂等性，不能实现跨会话的幂等性**。这里的会话，你可以理解为 Producer 进程的一次运行。当你重启了 Producer 进程之后，这种幂等性保证就丧失了

  - 事务（Transaction）

    - 目前主要是在 read committed 隔离级别上做事情。它能保证多条消息原子性地写入到目标分区，同时也能保证 Consumer 只能看到事务成功提交的消息

    - 设置事务性producer

      - 和幂等性 Producer 一样，开启 **enable.idempotence = true**。
      - 设置 Producer 端参数 ** transctional. id**。最好为其设置一个有意义的名字。

      ```java
      producer.initTransactions();
      try {
          producer.beginTransaction();
          producer.send(record1);
          producer.send(record2);
          producer.commitTransaction();
      } catch (KafkaException e) {
           producer.abortTransaction();
      }
      ```

    >  如果我想实现多分区以及多会话上的消息无重复，应该怎么做呢？答案就是事务（transaction）或者依赖事务型 Producer
    >
    > 幂等性 Producer 只能保证单分区、单会话上的消息幂等性；而事务能够保证跨分区、跨会话间的幂等性

### consumer group

- 如果所有实例都属于同一个 Group，那么它实现的就是消息队列模型；如果所有实例分别属于不同的 Group，那么它实现的就是发布 / 订阅模型。
- Rebalance 就是让一个 Consumer Group 下所有的 Consumer 实例就如何消费订阅主题的所有分区达成共识的过程,在 Rebalance 过程中，所有 Consumer 实例共同参与，在协调者组件的帮助下，完成订阅主题分区的分配。但是，在整个过程中，所有实例都不能消费任何消息，因此它对 Consumer 的 TPS 影响很大。

##### rebalance 触发条件,

1. 组成员数发生变更。比如有新的 Consumer 实例加入组或者离开组，抑或是有 Consumer 实例崩溃被“踢出”组。
   - 当 Consumer Group 完成 Rebalance 之后，每个 Consumer 实例都会定期地向 Coordinator  发送心跳请求，表明它还存活着。如果某个 Consumer 实例不能及时地发送这些心跳请求，Coordinator 就会认为该 Consumer  已经“死”了，从而将其从 Group 中移除，然后开启新一轮 Rebalance。Consumer 端有个参数，叫  session.timeout.ms，就是被用来表征此事的。该参数的默认值是 10 秒，即如果 Coordinator 在 10 秒之内没有收到 Group 下某 Consumer 实例的心跳，它就会认为这个 Consumer 实例已经挂了。可以这么说，**session.timout.ms **决定了 Consumer 存活性的时间间隔
   - Consumer 还提供了一个允许你控制发送心跳请求频率的参数，就是  **heartbeat.interval.ms**。这个值设置得越小，Consumer  实例发送心跳请求的频率就越高。频繁地发送心跳请求会额外消耗带宽资源，但好处是能够更加快速地知晓当前是否开启 Rebalance
2. 订阅主题数发生变更。Consumer Group 可以使用正则表达式的方式订阅主题，比如  consumer.subscribe(Pattern.compile(“t.*c”)) 就表明该 Group 订阅所有以字母 t 开头、字母 c 结尾的主题。在 Consumer Group 的运行过程中，你新创建了一个满足这样条件的主题，那么该 Group 就会发生  Rebalance。
3. 订阅主题的分区数发生变更。Kafka 当前只能允许增加一个主题的分区数。当分区数增加时，就会触发订阅该主题的所有 Group 开启 Rebalance。



- Rebalance 过程对 Consumer Group 消费过程有极大的影响。如果你了解 JVM  的垃圾回收机制，你一定听过万物静止的收集方式，即著名的 stop the world，简称 STW。在 STW  期间，所有应用线程都会停止工作，表现为整个应用程序僵在那边一动不动。Rebalance 过程也和这个类似，在 Rebalance 过程中，所有  Consumer 实例都会停止消费，等待 Rebalance 完成。这是 Rebalance 为人诟病的一个方面。



##### rebalance问题

1. Rebalance 影响 Consumer 端 TPS。这个之前也反复提到了，这里就不再具体讲了。总之就是，在 Rebalance 期间，Consumer 会停下手头的事情，什么也干不了。
2. Rebalance 很慢。如果你的 Group 下成员很多，就一定会有这样的痛点。还记得我曾经举过的那个国外用户的例子吧？他的 Group 下有几百个 Consumer 实例，Rebalance 一次要几个小时。在那种场景下，Consumer Group 的 Rebalance  已经完全失控了。
3. Rebalance 效率不高。当前 Kafka 的设计机制决定了每次 Rebalance 时，Group 下的所有成员都要参与进来，而且通常不会考虑局部性原理，但局部性原理对提升系统性能是特别重要的。

##### Coordinator

- 它专门为 Consumer Group 服务，负责为 Group 执行 Rebalance 以及提供位移管理和组成员管理等。

- Consumer 端应用程序在提交位移时，其实是向 Coordinator 所在的 Broker 提交位移。同样地，当 Consumer  应用启动时，也是向 Coordinator 所在的 Broker 发送各种请求，然后由 Coordinator  负责执行消费者组的注册、成员管理记录等元数据管理操作。

- 所有 Broker 在启动时，都会创建和开启相应的 Coordinator 组件。也就是说，**所有 Broker 都有各自的 Coordinator 组件**

- Kafka 为某个 Consumer Group 确定 Coordinator 所在的 Broker 的算法有 2 个步骤。

  1. 确定由位移主题的哪个分区来保存该 Group 数据：partitionId=Math.abs(groupId.hashCode() % offsetsTopicPartitionCount)。

  2. 找出该分区 Leader 副本所在的 Broker，该 Broker 即为对应的 Coordinator。

### __consumer_offsets

- **将 Consumer 的位移数据作为一条条普通的 Kafka 消息，提交到 __consumer_offsets 中。可以这么说，__consumer_offsets 的主要作用是保存 Kafka 消费者的位移信息。**它要求这个提交过程不仅要实现高持久性，还要支持高频的写操作

- **位移主题的 Key 中应该保存 3 部分内容：<Group ID，主题名，分区号 >**

- 当 Kafka 集群中的第一个 Consumer 程序启动时，**Kafka 会自动创建位移主题**

- 主题数与分区数

  - 设置分区数： offsets.topic.num.partitions       2.3版本默认值为1
  - 设置副本数：offsets.topic.replication.factor    2.3版本默认值为1

- 提交位移时，会写入到此主题，目前有两种提交方式

  - 手动提交位移
    - 禁止打开：  enable.auto.commit = false
    - 作为 Consumer 应用开发的你就要承担起位移提交的责任，consumer.commitSync
    - 
  - 自动提交位移  
    -  enable.auto.commit 设置为true
    - 提交间隔时间： auto.commit.interval.ms 
    - 优点：系统管理，客户端不用操心；缺点：丧失太多灵活性和可控性，没法把控consumer端的位移。

- **Kafka 是怎么删除位移主题中的过期消息的呢？答案就是 Compaction. Kafka 提供了专门的后台线程定期地巡检待 Compact 的主题，看看是否存在满足条件的可删除数据**。这个后台线程叫 Log Cleaner

  ![image-20201019000419450](assets/image-20201019000419450.png)

- 

